{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple Linear Regression With scikit-learn\n",
    "First, we need to import the appropriate packagaes and classes, which in this case are numpy and LinearRegression from sklearn.linear_model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second we need to define the data we will be working with; the inputs or regressors correspond to x and the outputs or predictors correspond to y. Both of them should be arrays or similar objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([5, 15, 25, 35, 45, 55]).reshape((-1, 1))\n",
    "y = np.array([5, 20, 14, 32, 22, 38])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the reshape() fucntion on x because this array needs to be two-dimensional, i.e. to have one column and as many rows as necessary. That is what the argument (-1, 1) of the function specifies. Then we need to take a look at the data, so we print it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5]\n",
      " [15]\n",
      " [25]\n",
      " [35]\n",
      " [45]\n",
      " [55]]\n",
      "[ 5 20 14 32 22 38]\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that we create a model and fit it with LinearRegression(). The default arguments are: \n",
    "- fit_intercept is a Boolean (True by default) that decides whether to calculate the intercept ğ‘â‚€ (True) or consider it equal to zero (False).\n",
    "- normalize is a Boolean (False by default) that decides whether to normalize the input variables (True) or not (False).\n",
    "- copy_X is a Boolean (True by default) that decides whether to copy (True) or overwrite the input variables (False).\n",
    "- n_jobs is an integer or None (default) and represents the number of jobs used in parallel computation. None usually means one job and -1 to use all processors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, with .fit(), we calculate the optimal values of the weights ğ‘â‚€ and ğ‘â‚, using the existing input and output (x and y) as the arguments, i.e. we fit the model. We can do both of this steps in one with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting the model, we can get the results to make sure it is functional. In this case, the arguments are x and y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination: 0.715875613747954\n"
     ]
    }
   ],
   "source": [
    "r_sq = model.score(x, y)\n",
    "print('coefficient of determination:', r_sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attributes of the model are .intercept_, which represents the coefficient, ğ‘â‚€ (y intercept) and .coef_, which represents ğ‘1 (the slope):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: 5.633333333333329\n",
      "slope: [0.54]\n"
     ]
    }
   ],
   "source": [
    "print('intercept:', model.intercept_)\n",
    "print('slope:', model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take notice that .intercept_ is a scalar, while .coef_ is an array. This results tell us that the model predicts the response 5.63 when ğ‘¥ is zero. The value ğ‘â‚ = 0.54 means that the predicted response rises by 0.54 when ğ‘¥ is increased by one. We can provide y as a 2-dimensional array by doing the following, which returns similar results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: [5.63333333]\n",
      "slope: [[0.54]]\n"
     ]
    }
   ],
   "source": [
    "new_model = LinearRegression().fit(x, y.reshape((-1, 1)))\n",
    "print('intercept:', new_model.intercept_)\n",
    "print('slope:', new_model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict responses we use the predict() function, which passes the regressor as the argument and returns the corresponding predicted response: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted response:\n",
      "[ 8.33333333 13.73333333 19.13333333 24.53333333 29.93333333 35.33333333]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x)\n",
    "print('predicted response:', y_pred, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do the following, which multiplies each element of x with model.coef_ and add model.intercept_ to the product. The predicted response is now a two-dimensional array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted response:\n",
      "[[ 8.33333333]\n",
      " [13.73333333]\n",
      " [19.13333333]\n",
      " [24.53333333]\n",
      " [29.93333333]\n",
      " [35.33333333]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.intercept_ + model.coef_ * x\n",
    "print('predicted response:', y_pred, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since regression models are often applied for forecasts, we can use fitted models to calculate the outputs based on some other, new inputs. In the following example, .predict() is applied to the new regressor x_new and yields the response y_new. This example conveniently uses arange() from numpy to generate an array with the elements from 0 (inclusive) to 5 (exclusive), i.e. 0,1,2,3,4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n"
     ]
    }
   ],
   "source": [
    "x_new = np.arange(5).reshape((-1, 1))\n",
    "print(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.63333333 6.17333333 6.71333333 7.25333333 7.79333333]\n"
     ]
    }
   ],
   "source": [
    "y_new = model.predict(x_new)\n",
    "print(y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multiple Linear Regression With scikit-learn\n",
    "As before, we first import numpy and LinearRegression from sklearn.linear_model. We will not doing again as these packages have been imported already. We then provide known inputs and outputs and print them to make sure they are what we want. In this type of regression, x is a two-dimensional array with at least two columns (exactly two in this case), while y is usually a one-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1]\n",
      " [ 5  1]\n",
      " [15  2]\n",
      " [25  5]\n",
      " [35 11]\n",
      " [45 15]\n",
      " [55 34]\n",
      " [60 35]]\n",
      "[ 4  5 20 14 32 22 38 43]\n"
     ]
    }
   ],
   "source": [
    "x = [[0, 1], [5, 1], [15, 2], [25, 5], [35, 11], [45, 15], [55, 34], [60, 35]]\n",
    "y = [4, 5, 20, 14, 32, 22, 38, 43]\n",
    "x, y = np.array(x), np.array(y)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we fit the model and get its properties as we did before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination: 0.8615939258756776\n",
      "intercept: 5.52257927519819\n",
      "slope: [0.44706965 0.25502548]\n"
     ]
    }
   ],
   "source": [
    "r_sq = model.score(x, y)\n",
    "print('coefficient of determination:', r_sq)\n",
    "print('intercept:', model.intercept_)\n",
    "print('slope:', model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get ğ‘…Â² using .score() and the values of the estimators of regression coefficients with .intercept_ (ğ‘â‚€) and .coef_ (ğ‘â‚ and ğ‘â‚‚). In this example, the intercept is approximately 5.52, i.e. the value of the predicted response when ğ‘¥â‚ = ğ‘¥â‚‚ = 0. The increase of ğ‘¥â‚ by 1 yields the rise of the predicted response by 0.45. Similarly, when ğ‘¥â‚‚ grows by 1, the response rises by 0.26."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions work the same way as with simple linear regression: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted response:\n",
      "[ 5.77760476  8.012953   12.73867497 17.9744479  23.97529728 29.4660957\n",
      " 38.78227633 41.27265006]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x)\n",
    "print('predicted response:', y_pred, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do it the following way, which yields similar results. In this case, we predict the output values by multiplying each column of the input with the appropriate weight, summing the results and adding the intercept to the sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted response:\n",
      "[ 5.77760476  8.012953   12.73867497 17.9744479  23.97529728 29.4660957\n",
      " 38.78227633 41.27265006]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.intercept_ + np.sum(model.coef_ * x, axis=1)\n",
    "print('predicted response:', y_pred, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can apply this model to new data as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [6 7]\n",
      " [8 9]]\n"
     ]
    }
   ],
   "source": [
    "x_new = np.arange(10).reshape((-1, 2))\n",
    "print(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.77760476  7.18179502  8.58598528  9.99017554 11.3943658 ]\n"
     ]
    }
   ],
   "source": [
    "y_new = model.predict(x_new)\n",
    "print(y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Polynomial Regression With scikit-learn\n",
    "In this case, we need the same packages as before plus PolynomialFeatures class from sklearn.preprocessing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the regressors and predictors are defined the same way as before. Since we need the input to be a two-dimensional array, we use .reshape(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([5, 15, 25, 35, 45, 55]).reshape((-1, 1))\n",
    "y = np.array([15, 11, 2, 8, 25, 32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a new step when doing polynomial regression. We need to include ğ‘¥Â² as an additional feature, so we should transform the input array x to contain the additional column(s) with the values of ğ‘¥Â² (and eventually other features if needed). The class PolynomialFeatures is very convenient for this purpose. In this case the variable transformer refers to an instance of PolynomialFeatures which you can use to transform the input x. The defaults are:\n",
    "- degree is an integer (2 by default) that represents the degree of the polynomial regression function.\n",
    "- interaction_only is a Boolean (False by default) that decides whether to include only interaction features (True) or all features (False).\n",
    "- include_bias is a Boolean (True by default) that decides whether to include the bias (intercept) column of ones (True) or not (False)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = PolynomialFeatures(degree=2, include_bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the transformer variable set, we need to fit it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolynomialFeatures(degree=2, include_bias=False, interaction_only=False,\n",
       "                   order='C')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.fit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The, transformer is ready to create a new, modified input, applying .transform(), which takes the input array as the argument and returns the modified array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = transformer.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the three past statements in one, we can do the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modified array will look the following way, one column with the original inputs and the other with their squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   5.   25.]\n",
      " [  15.  225.]\n",
      " [  25.  625.]\n",
      " [  35. 1225.]\n",
      " [  45. 2025.]\n",
      " [  55. 3025.]]\n"
     ]
    }
   ],
   "source": [
    "print(x_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then fit the model as we did before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(x_, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain the properties of the model, the same way as we did before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination: 0.8908516262498564\n",
      "intercept: 21.372321428571425\n",
      "coefficients: [-1.32357143  0.02839286]\n"
     ]
    }
   ],
   "source": [
    "r_sq = model.score(x_, y)\n",
    "print('coefficient of determination:', r_sq)\n",
    "print('intercept:', model.intercept_)\n",
    "print('coefficients:', model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before: .score() returns ğ‘…Â². Its first argument is also the modified input x_, not x. The values of the weights are associated to .intercept_ and .coef_: .intercept_ represents ğ‘â‚€, while .coef_ references the array that contains ğ‘â‚ and ğ‘â‚‚ respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain similar results, with different transformation and regression arguments, like setting the include_bias to true, which yields three columns: the first column of x_ contains ones, the second has the values of x, while the third holds the squares of x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.000e+00 5.000e+00 2.500e+01]\n",
      " [1.000e+00 1.500e+01 2.250e+02]\n",
      " [1.000e+00 2.500e+01 6.250e+02]\n",
      " [1.000e+00 3.500e+01 1.225e+03]\n",
      " [1.000e+00 4.500e+01 2.025e+03]\n",
      " [1.000e+00 5.500e+01 3.025e+03]]\n"
     ]
    }
   ],
   "source": [
    "x_ = PolynomialFeatures(degree=2, include_bias=True).fit_transform(x)\n",
    "print(x_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the intercept is already included with the leftmost column of ones, we donâ€™t need to include it again when creating the instance of LinearRegression, meaning we can provide fit_intercept=False, the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=False).fit(x_, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then get the results, which are similar to the ones we had before. Now .intercept_ is zero, but .coef_ actually contains ğ‘â‚€ as its first element: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination: 0.8908516262498565\n",
      "intercept: 0.0\n",
      "coefficients: [21.37232143 -1.32357143  0.02839286]\n"
     ]
    }
   ],
   "source": [
    "r_sq = model.score(x_, y)\n",
    "print('coefficient of determination:', r_sq)\n",
    "print('intercept:', model.intercept_)\n",
    "print('coefficients:', model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a predicted response, we do the same as before, but must include the x_ argument instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted response:\n",
      "[15.46428571  7.90714286  6.02857143  9.82857143 19.30714286 34.46428571]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_)\n",
    "print('predicted response:', y_pred, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can follow a similar procedure with several input variables. We'll have an input array with more than one column, but everything else is the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import packages\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Step 2a: Provide data\n",
    "x = [[0, 1], [5, 1], [15, 2], [25, 5], [35, 11], [45, 15], [55, 34], [60, 35]]\n",
    "y = [4, 5, 20, 14, 32, 22, 38, 43]\n",
    "x, y = np.array(x), np.array(y)\n",
    "\n",
    "# Step 2b: Transform input data\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x)\n",
    "\n",
    "# Step 3: Create a model and fit it\n",
    "model = LinearRegression().fit(x_, y)\n",
    "\n",
    "# Step 4: Get results\n",
    "r_sq = model.score(x_, y)\n",
    "intercept, coefficients = model.intercept_, model.coef_\n",
    "\n",
    "# Step 5: Predict\n",
    "y_pred = model.predict(x_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This regression example yields the following results and predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination: 0.9453701449127822\n",
      "intercept: 0.8430556452395734\n",
      "coefficients:\n",
      "[ 2.44828275  0.16160353 -0.15259677  0.47928683 -0.4641851 ]\n",
      "predicted response:\n",
      "[ 0.54047408 11.36340283 16.07809622 15.79139    29.73858619 23.50834636\n",
      " 39.05631386 41.92339046]\n"
     ]
    }
   ],
   "source": [
    "print('coefficient of determination:', r_sq)\n",
    "print('intercept:', intercept)\n",
    "print('coefficients:', coefficients, sep='\\n')\n",
    "print('predicted response:', y_pred, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, there are six regression coefficients (including the intercept), as shown in the estimated regression function ğ‘“(ğ‘¥â‚, ğ‘¥â‚‚) = ğ‘â‚€ + ğ‘â‚ğ‘¥â‚ + ğ‘â‚‚ğ‘¥â‚‚ + ğ‘â‚ƒğ‘¥â‚Â² + ğ‘â‚„ğ‘¥â‚ğ‘¥â‚‚ + ğ‘â‚…ğ‘¥â‚‚Â².\n",
    "\n",
    "You can also notice that polynomial regression yielded a higher coefficient of determination than multiple linear regression for the same problem. At first, you could think that obtaining such a large ğ‘…Â² is an excellent result. It might be.\n",
    "\n",
    "However, in real-world situations, having a complex model and ğ‘…Â² very close to 1 might also be a sign of overfitting. To check the performance of a model, you should test it with new data, that is with observations not used to fit (train) the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced Linear Regression With statsmodels\n",
    "We can implement linear regression in Python relatively easily by using the package statsmodels as well. We first need to import it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/LEBC/anaconda3/lib/python3.7/site-packages/statsmodels/compat/pandas.py:23: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  data_klasses = (pandas.Series, pandas.DataFrame, pandas.Panel)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then provide data and transform inputs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[0, 1], [5, 1], [15, 2], [25, 5], [35, 11], [45, 15], [55, 34], [60, 35]]\n",
    "y = [4, 5, 20, 14, 32, 22, 38, 43]\n",
    "x, y = np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input and output arrays are created this way, but then we need to add the column of ones to the inputs if you want statsmodels to calculate the intercept ğ‘â‚€ since it doesnâ€™t takes ğ‘â‚€ into account by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sm.add_constant(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You add the column of ones to x with add_constant(), which takes the input array x as an argument and returns a new array with the column of ones inserted at the beginning. This is how x and y look like now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  1.]\n",
      " [ 1.  5.  1.]\n",
      " [ 1. 15.  2.]\n",
      " [ 1. 25.  5.]\n",
      " [ 1. 35. 11.]\n",
      " [ 1. 45. 15.]\n",
      " [ 1. 55. 34.]\n",
      " [ 1. 60. 35.]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  5 20 14 32 22 38 43]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression model based on ordinary least squares is an instance of the class statsmodels.regression.linear_model.OLS. The first argument is the output, followed with the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model as we did before: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to get the results we just use the summary() function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.862\n",
      "Model:                            OLS   Adj. R-squared:                  0.806\n",
      "Method:                 Least Squares   F-statistic:                     15.56\n",
      "Date:                Sat, 05 Oct 2019   Prob (F-statistic):            0.00713\n",
      "Time:                        16:05:26   Log-Likelihood:                -24.316\n",
      "No. Observations:                   8   AIC:                             54.63\n",
      "Df Residuals:                       5   BIC:                             54.87\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          5.5226      4.431      1.246      0.268      -5.867      16.912\n",
      "x1             0.4471      0.285      1.567      0.178      -0.286       1.180\n",
      "x2             0.2550      0.453      0.563      0.598      -0.910       1.420\n",
      "==============================================================================\n",
      "Omnibus:                        0.561   Durbin-Watson:                   3.268\n",
      "Prob(Omnibus):                  0.755   Jarque-Bera (JB):                0.534\n",
      "Skew:                           0.380   Prob(JB):                        0.766\n",
      "Kurtosis:                       1.987   Cond. No.                         80.1\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/LEBC/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:1450: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=8\n",
      "  \"anyway, n=%i\" % int(n))\n"
     ]
    }
   ],
   "source": [
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract values from the table above, we can do the following, where:\n",
    "1. .rsquared holds ğ‘…Â².\n",
    "2. .rsquared_adj represents adjusted ğ‘…Â² (ğ‘…Â² corrected according to the number of input features).\n",
    "3. .params refers the array with ğ‘â‚€, ğ‘â‚, and ğ‘â‚‚ respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination: 0.8615939258756777\n",
      "adjusted coefficient of determination: 0.8062314962259488\n",
      "regression coefficients: [5.52257928 0.44706965 0.25502548]\n"
     ]
    }
   ],
   "source": [
    "print('coefficient of determination:', results.rsquared)\n",
    "print('adjusted coefficient of determination:', results.rsquared_adj)\n",
    "print('regression coefficients:', results.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain the predicted response on the input values used for creating the model using .fittedvalues or .predict() with the input array as the argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted response:\n",
      "[ 5.77760476  8.012953   12.73867497 17.9744479  23.97529728 29.4660957\n",
      " 38.78227633 41.27265006]\n",
      "predicted response:\n",
      "[ 5.77760476  8.012953   12.73867497 17.9744479  23.97529728 29.4660957\n",
      " 38.78227633 41.27265006]\n"
     ]
    }
   ],
   "source": [
    "# fittedvalues\n",
    "print('predicted response:', results.fittedvalues, sep='\\n')\n",
    "# predict\n",
    "print('predicted response:', results.predict(x), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want predictions with new regressors, you can also apply .predict() with new data as the argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 1.]\n",
      " [1. 2. 3.]\n",
      " [1. 4. 5.]\n",
      " [1. 6. 7.]\n",
      " [1. 8. 9.]]\n"
     ]
    }
   ],
   "source": [
    "x_new = sm.add_constant(np.arange(10).reshape((-1, 2)))\n",
    "print(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.77760476  7.18179502  8.58598528  9.99017554 11.3943658 ]\n"
     ]
    }
   ],
   "source": [
    "y_new = results.predict(x_new)\n",
    "print(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
